{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If you use the pickle file -- Skip to that cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../LeapMotion/Leap_Motion_Data/\")\n",
    "\n",
    "glob_list = []\n",
    "\n",
    "#loop through subject folders and glob\n",
    "for subject in range(25):\n",
    "    # Change slashes if on windows to \\\\\n",
    "    glob_list.append(sorted(glob.glob(str(subject) + \"/[A-Z0-9]*.csv\")))\n",
    "    \n",
    "#function to flatten glob\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "glob_list = flatten(glob_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a list of tuples of hand pairings\n",
    "lr_pairs = list(zip(*[iter(glob_list)]*2))\n",
    "\n",
    "# remove all blue files\n",
    "for i in range(25):\n",
    "    # Change slashes if on windows to \\\\\n",
    "    lr_pairs.remove((str(i)+'/Blue_Left.csv', str(i)+'/Blue_Right.csv'))\n",
    "# remove \"bad\" from subject 19\n",
    "# Change slashes if on windows to \\\\\n",
    "lr_pairs.remove(('19/Bad_Left.csv', '19/Bad_Right.csv'))\n",
    "print(lr_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create list of DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "for pair in lr_pairs:\n",
    "    df_left = pd.read_csv(pair[0], index_col=None).drop(['Unnamed: 0'], axis = 1)\n",
    "    df_right = pd.read_csv(pair[1], index_col=None).drop(['Unnamed: 0'], axis = 1)\n",
    "    \n",
    "    #rename columns\n",
    "    df_left = df_left.add_prefix('left')\n",
    "    df_right = df_right.add_prefix('right')\n",
    "    \n",
    "    #merge\n",
    "    df = pd.merge(df_left, df_right, left_on='leftTime', right_on='rightTime').drop('rightTime', axis = 1)\n",
    "\n",
    "    #covert fist column to time object\n",
    "    df['leftTime'] = pd.to_datetime(df['leftTime'].str[:-3], format = '%H:%M:%S.%f')\n",
    "    \n",
    "    #difference between rows\n",
    "    df = df.diff().iloc[1:]\n",
    "    df['leftTime'] = df['leftTime'].dt.total_seconds()\n",
    "    \n",
    "    df.rename(columns={'leftTime':'time'}, inplace=True)\n",
    "    \n",
    "    #add sign and subject using regex of file name\n",
    "    # Change slashes if on windows to \\\\\n",
    "    subject_sign = re.split(r'/', re.findall('^[^_]+(?=_)', pair[0])[0])\n",
    "    print(subject_sign)\n",
    "    df.insert(loc = 0, column = 'Subject', value = subject_sign[0])\n",
    "    df.insert(loc = 0, column = 'Sign', value = subject_sign[1])\n",
    "    \n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle the dataframe list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('sign_frames.pkl', 'wb') as f:\n",
    "    pickle.dump(df_list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataframe from pickle instead of remaking the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import timeit\n",
    "# This line may need to be commented/uncommented as needed\n",
    "#os.chdir(\"../LeapMotion/Leap_Motion_Data/\")\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "with open('sign_frames.pkl', 'rb') as f:\n",
    "    df_list = pickle.load(f)\n",
    "# code you want to evaluate\n",
    "elapsed = timeit.default_timer() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.70063448600001"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of signs included in data set\n",
    "os.chdir(\"..\")\n",
    "hands_used  = pd.read_csv(\"signs_f.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = [(abs(df.iloc[:,3:].filter(regex='left').mean().sum()), df.loc[1, 'Sign']) for df in df_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = .000025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hand = [tup[1] for tup in threshold if tup[0] < thresh]\n",
    "one_hand = list(set(one_hand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "two_hand = [value for value in hands_used.Sign.values if value not in one_hand]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hand_selection:\n",
    "    \n",
    "    def __init__(self, drop_left=False):\n",
    "        self.drop_left = drop_left\n",
    "        \n",
    "    def transform(self, df_list, hand_list):\n",
    "        if not self.drop_left:\n",
    "            subset = [df for df in df_list if df.Sign.values[0] in hand_list]\n",
    "        else:\n",
    "            subset = [df.drop(df.filter(regex='left').columns, axis=1) \\\n",
    "                      for df in df_list \\\n",
    "                      if df.Sign.values[0] in hand_list]\n",
    "            \n",
    "        return subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class extraction:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.features = dict()\n",
    "        \n",
    "    def label(self):\n",
    "        self.features['label'] = self.df['Sign'].iloc[0]\n",
    "        self.df = self.df.iloc[:, 2:]\n",
    "        \n",
    "    def mean(self):\n",
    "        for col in self.df:\n",
    "            self.features[col + ' mean'] = self.df[col].mean()\n",
    "            \n",
    "    def stdev(self):\n",
    "        for col in self.df:\n",
    "            self.features[col + ' stdev'] = self.df[col].std()\n",
    "            \n",
    "    def extract_features(self):\n",
    "        self.label()\n",
    "        self.mean()\n",
    "        self.stdev()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def return_features(df_list, hand_list, drop_left):\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    feature_list = []\n",
    "    \n",
    "    select_class = hand_selection(drop_left)\n",
    "    frames = select_class.transform(df_list, hand_list)\n",
    "    \n",
    "    for df in frames:\n",
    "        class_obj = extraction(df)\n",
    "        class_obj.extract_features()\n",
    "        feature_list.append(class_obj.features)\n",
    "        \n",
    "    feat_df = pd.DataFrame(feature_list)\n",
    "    \n",
    "    y = feat_df.label\n",
    "    X = scaler.fit_transform(feat_df.drop(['label'], axis = 1))\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_one_hand, y_one_hand = return_features(df_list=df_list, \n",
    "                                         hand_list=one_hand, \n",
    "                                         drop_left=True)\n",
    "\n",
    "X_two_hand, y_two_hand = return_features(df_list=df_list, \n",
    "                                         hand_list=two_hand, \n",
    "                                         drop_left=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "lda_accuracy = []\n",
    "qda_accuracy = []\n",
    "knn_accuracy = []\n",
    "rf_accuracy = []\n",
    "nb_accuracy = []\n",
    "svm_accuracy = []\n",
    "\n",
    "for i in range(100):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_two_hand, \n",
    "                                                        y_two_hand,\n",
    "                                                        stratify=y_two_hand, \n",
    "                                                        test_size=0.25)\n",
    "\n",
    "    clf = LinearDiscriminantAnalysis()\n",
    "    clf.fit(X_train, y_train)\n",
    "    lda_accuracy.append(clf.score(X_test,y_test))\n",
    "    \n",
    "    clf = SVC(decision_function_shape='ovo', kernel='linear', C=1, gamma=1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    svm_accuracy.append(clf.score(X_test, y_test))\n",
    "    \n",
    "    \n",
    "    clf = QuadraticDiscriminantAnalysis()\n",
    "    clf.fit(X_train, y_train)\n",
    "    qda_accuracy.append(clf.score(X_test,y_test))\n",
    "    \n",
    "    neigh = KNeighborsClassifier(n_neighbors=15)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    knn_accuracy.append(neigh.score(X_test,y_test))    \n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    rf_accuracy.append(clf.score(X_test,y_test))\n",
    "\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    nb_accuracy.append(clf.score(X_test,y_test))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list = [qda_accuracy, nb_accuracy, knn_accuracy, rf_accuracy, lda_accuracy, svm_accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5.5, 5.5))\n",
    "plt.ylim(0, 1)\n",
    "plt.boxplot(accuracy_list, labels = ['QDA', 'Naive Bayes', 'k-nn', 'Random Forest', 'LDA', 'SVM'])\n",
    "plt.title('Two-Handed Model Performance')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('plots/two_hand_model_performance_svm_ovo_linear_kernel.png', dpi = 500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(lda_accuracy))\n",
    "print(max(svm_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_accuracy = []\n",
    "qda_accuracy = []\n",
    "knn_accuracy = []\n",
    "rf_accuracy = []\n",
    "nb_accuracy = []\n",
    "svm_accuracy = []\n",
    "\n",
    "for i in range(100):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_one_hand, \n",
    "                                                        y_one_hand,\n",
    "                                                        stratify=y_one_hand, \n",
    "                                                        test_size=0.25)\n",
    "    clf = LinearDiscriminantAnalysis()\n",
    "    clf.fit(X_train, y_train)\n",
    "    lda_accuracy.append(clf.score(X_test,y_test))\n",
    "    \n",
    "    clf = SVC(decision_function_shape='ovo', kernel='linear', C=1, gamma=1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    svm_accuracy.append(clf.score(X_test, y_test))\n",
    "    svm_accuracy.append(clf.score(X_test, y_test))\n",
    "    \n",
    "    clf = QuadraticDiscriminantAnalysis()\n",
    "    clf.fit(X_train, y_train)\n",
    "    qda_accuracy.append(clf.score(X_test,y_test))\n",
    "    \n",
    "    neigh = KNeighborsClassifier(n_neighbors=15)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    knn_accuracy.append(neigh.score(X_test,y_test))    \n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    rf_accuracy.append(clf.score(X_test,y_test))\n",
    "\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    nb_accuracy.append(clf.score(X_test,y_test))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(lda_accuracy))\n",
    "print(max(svm_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list = [qda_accuracy, nb_accuracy, knn_accuracy, rf_accuracy, lda_accuracy, svm_accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5.5, 5.5))\n",
    "plt.ylim(0, 1)\n",
    "plt.boxplot(accuracy_list, labels = ['QDA', 'Naive Bayes', 'k-nn', 'Random Forest', 'LDA', 'SVM'])\n",
    "plt.title('One-Handed Model Performance')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('plots/one_hand_model_performance.png', dpi = 500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "accuracy_two_hand = []\n",
    "\n",
    "for i in range(100):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_two_hand, \n",
    "                                                        y_two_hand,\n",
    "                                                        stratify=y_two_hand, \n",
    "                                                        test_size=0.25)\n",
    "\n",
    "    clf = LinearDiscriminantAnalysis()\n",
    "    clf.fit(X_train, y_train)\n",
    "    #clf.scalings_\n",
    "    accuracy_two_hand.append(clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_one_hand = []\n",
    "\n",
    "for i in range(100):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_one_hand, \n",
    "                                                        y_one_hand,\n",
    "                                                        stratify=y_one_hand, \n",
    "                                                        test_size=0.25)\n",
    "\n",
    "    clf = LinearDiscriminantAnalysis()\n",
    "    clf.fit(X_train, y_train)\n",
    "    #clf.scalings_\n",
    "    accuracy_one_hand.append(clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(accuracy_one_hand, bins=10, label = 'One hand', alpha=0.5)\n",
    "plt.hist(accuracy_two_hand, bins=10, label = 'Two hand', alpha=0.5)\n",
    "plt.xlabel(\"Classification Accuracy\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig('plots/lda_both_hands.png', dpi = 750)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_two_hand, \n",
    "                                                    y_two_hand,\n",
    "                                                    stratify=y_two_hand, \n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state = 42)\n",
    "\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "two_hand_pred = pd.DataFrame(zip(y_test, clf.predict(X_test)), columns=['actual', 'predicted'])\n",
    "\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_one_hand, \n",
    "                                                    y_one_hand,\n",
    "                                                    stratify=y_one_hand, \n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state = 42)\n",
    "\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "one_hand_pred = pd.DataFrame(zip(y_test, clf.predict(X_test)), columns=['actual', 'predicted'])\n",
    "\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pred = pd.concat([one_hand_pred, two_hand_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclass = combined_pred[combined_pred.actual != combined_pred.predicted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "misclass_groupby = misclass.groupby(['actual', 'predicted'])[['predicted']].agg('count')\n",
    "misclass_groupby[misclass_groupby > 1].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of times a sign is misclassified (False Negative):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(misclass.groupby(['actual'])[['predicted']].agg('count')['predicted'].sort_values(ascending = False)).iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of times a sign is incorrectly assigned (False Poitive):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(misclass.groupby(['predicted'])[['predicted']].agg('count')['predicted'].sort_values(ascending = False)).iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Versus All ROC Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_two_hand, \n",
    "                                                    label_binarize(y_two_hand, classes=two_hand),\n",
    "                                                    stratify=label_binarize(y_two_hand, classes=two_hand), \n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state = 42)\n",
    "\n",
    "clf = OneVsRestClassifier(LinearDiscriminantAnalysis())\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_score = clf.fit(X_train, y_train).decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = two_hand\n",
    "n_classes = len(labels)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot of a ROC curve for a specific class\n",
    "for i in range(n_classes):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC ' + labels[i])\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('plots/' + labels[i] + '.png', dpi = 750)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_one_hand, \n",
    "                                                    label_binarize(y_one_hand, classes=one_hand),\n",
    "                                                    stratify=label_binarize(y_one_hand, classes=one_hand), \n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state = 42)\n",
    "\n",
    "clf = OneVsRestClassifier(LinearDiscriminantAnalysis())\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_score = clf.fit(X_train, y_train).decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = one_hand\n",
    "n_classes = len(labels)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot of a ROC curve for a specific class\n",
    "for i in range(n_classes):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC ' + labels[i])\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('plots/' + labels[i] + '.png', dpi = 750)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
